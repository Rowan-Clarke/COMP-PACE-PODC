{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61b63773",
   "metadata": {},
   "source": [
    "The following script utilises OpenAi's 'File-search tool', implemented in a simple terminal-based chat application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8395ee84",
   "metadata": {},
   "source": [
    "In order to run this application, the following steps are required:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f70bcf",
   "metadata": {},
   "source": [
    "1. Install the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f7ef1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai rich"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cd83b6",
   "metadata": {},
   "source": [
    "2. Set your OpenAI API key as an environmental variable or enter it when prompted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb1738b",
   "metadata": {},
   "source": [
    "Windows Set-up\n",
    "- Run the following in the cmd prompt, replacing <yourkey> with your API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1246e00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "setx OPENAI_API_KEY \"<yourkey>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7d4f0b",
   "metadata": {},
   "source": [
    "3. Run the script: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b43a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "python conversation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583b716a",
   "metadata": {},
   "source": [
    "To improve the effectiveness of the Chat application in providing up-to-date, reliable results - the chatbot utilises 'Vector stores' via the openai API Storage Dashboard. \n",
    "\n",
    "\n",
    "(INSERT IMAGE OF VECTOR STORE EXAMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cd4074",
   "metadata": {},
   "source": [
    "In this example, two websites - specifically recommended by POCD - have been 'scraped', converted into seperate txt. files, and stored in our vector store.\n",
    "\n",
    "These websites are titled:\n",
    "                             ' Describing the serverity of a hearing loss loss ' - Aussie Deaf Kids\n",
    "                             ' Describing hearing loss ' - Aussie Deaf Kids\n",
    "\n",
    "\n",
    "These websites have been converted into txt, as seen in the folder of this repository 'output_txt_files'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48631ed6",
   "metadata": {},
   "source": [
    "To utilise this vector store, the ID (vs_6801d393c83c819184cad189cc621a23), has been specified in our application. This ID is specific to my (Dylan's) OpenAI dashboard environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0385b022",
   "metadata": {},
   "source": [
    "Listed below, is an explanation of each part of the application's infrastructure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfc52e3",
   "metadata": {},
   "source": [
    "Package importation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eddd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from rich.console import Console\n",
    "from rich.markdown import Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85eb73e",
   "metadata": {},
   "source": [
    "Initialising the OpenAI client:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c803a7ed",
   "metadata": {},
   "source": [
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not openai_api_key:\n",
    "    openai_api_key = input(\"Please enter your OpenAI API key: \")\n",
    "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "\n",
    "client = openai.OpenAI(api_key=openai_api_key)\n",
    "console = Console()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1671eb09",
   "metadata": {},
   "source": [
    "Vector store ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e91b1f1",
   "metadata": {},
   "source": [
    "VECTOR_STORE_ID = \"vs_6801d393c83c819184cad189cc621a23\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df13a708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_markdown(text):\n",
    "    \"\"\"Print text as markdown.\"\"\"\n",
    "    console.print(Markdown(text))\n",
    "\n",
    "def chat_with_file_search():\n",
    "    \"\"\"Main chat loop with file search capabilities.\"\"\"\n",
    "    console.print(\"[bold green]File Search Enabled Chat[/bold green]\")\n",
    "    console.print(\"[italic]Type 'exit' to quit the chat[/italic]\")\n",
    "    console.print()\n",
    "    \n",
    "    previous_response_id = None\n",
    "    \n",
    "    while True:\n",
    "        # Get user input\n",
    "        user_input = input(\"\\n[You]: \")\n",
    "        \n",
    "        if user_input.lower() == 'exit':\n",
    "            console.print(\"[bold green]Thank you for chatting![/bold green]\")\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            # Create a response with file search tool\n",
    "            response = client.responses.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                input=user_input,\n",
    "                previous_response_id=previous_response_id,\n",
    "                tools=[{\n",
    "                    \"type\": \"file_search\",\n",
    "                    \"vector_store_ids\": [VECTOR_STORE_ID]\n",
    "                }],\n",
    "                include=[\"file_search_call.results\"]\n",
    "            )\n",
    "            \n",
    "            # Save the response ID for conversation continuity\n",
    "            previous_response_id = response.id\n",
    "            \n",
    "            # Print the assistant's response\n",
    "            console.print(\"\\n[Assistant]:\", style=\"bold blue\")\n",
    "            print_markdown(response.output_text)\n",
    "            \n",
    "            # If file search was used, print the citations\n",
    "            if hasattr(response, 'file_search_calls') and response.file_search_calls:\n",
    "                console.print(\"\\n[Citations]:\", style=\"bold yellow\")\n",
    "                for file_search_call in response.file_search_calls:\n",
    "                    if hasattr(file_search_call, 'search_results') and file_search_call.search_results:\n",
    "                        for i, result in enumerate(file_search_call.search_results, 1):\n",
    "                            console.print(f\"[{i}] File: {result.file.filename}\")\n",
    "                            console.print(f\"    Excerpt: {result.text[:100]}...\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            console.print(f\"\\n[bold red]Error: {str(e)}[/bold red]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f214a8",
   "metadata": {},
   "source": [
    "Verification of valid API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3291ddaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Check if the API key is valid\n",
    "    try:\n",
    "        client.models.list()\n",
    "        chat_with_file_search()\n",
    "    except Exception as e:\n",
    "        console.print(f\"[bold red]Failed to initialize: {str(e)}[/bold red]\")\n",
    "        console.print(\"[bold yellow]Make sure your API key is correct and has access to the file search feature.[/bold yellow]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb50cdac",
   "metadata": {},
   "source": [
    "Listed below is an example of the chatbot in a terminal-based environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6d49fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">File Search Enabled Chat</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mFile Search Enabled Chat\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">Type </span><span style=\"color: #008000; text-decoration-color: #008000; font-style: italic\">'exit'</span><span style=\"font-style: italic\"> to quit the chat</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3mType \u001b[0m\u001b[3;32m'exit'\u001b[0m\u001b[3m to quit the chat\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[Assistant]:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34m[\u001b[0m\u001b[1;34mAssistant\u001b[0m\u001b[1;34m]\u001b[0m\u001b[1;34m:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Hello! How can I assist you today with the files you've uploaded?                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Hello! How can I assist you today with the files you've uploaded?                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[Assistant]:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34m[\u001b[0m\u001b[1;34mAssistant\u001b[0m\u001b[1;34m]\u001b[0m\u001b[1;34m:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Hearing loss is measured using audiometry, which evaluates individuals' ability to hear sounds at different        \n",
       "frequencies and intensities. Here's how it is categorized:                                                         \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">Severity Levels</span>:                                                                                                \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">Mild (21-40 dB)</span>: Difficulty hearing soft or distant speech; normal conversation may be hard in noisy         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>environments.                                                                                                \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">Moderate (41-70 dB)</span>: Requires hearing aids to understand normal speech; relies on speechreading cues.        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">Severe (71-90 dB)</span>: Understanding normal speech is very challenging even with aids; may hear loud sounds at   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>close distances.                                                                                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">Profound (91 dB and above)</span>: Limited ability to understand conversational speech; often utilize cochlear      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>implants rather than traditional hearing aids.                                                               \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">Types of Hearing Loss</span>:                                                                                          \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">Conductive</span>: Occurs when sound cannot travel freely through the outer and middle ear.                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">Sensorineural</span>: Caused by issues within the inner ear or auditory nerve, often permanent.                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">Mixed</span>: Combination of conductive and sensorineural loss.                                                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">Audiogram</span>: Results are represented graphically on an audiogram, which illustrates the degree of hearing loss    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>across various frequencies and can show if the loss is symmetrical (similar in both ears) or asymmetrical       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>(different in each ear).                                                                                        \n",
       "\n",
       "These methods help determine the type and severity of hearing loss, guiding appropriate interventions and support. \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Hearing loss is measured using audiometry, which evaluates individuals' ability to hear sounds at different        \n",
       "frequencies and intensities. Here's how it is categorized:                                                         \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1mSeverity Levels\u001b[0m:                                                                                                \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mMild (21-40 dB)\u001b[0m: Difficulty hearing soft or distant speech; normal conversation may be hard in noisy         \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0menvironments.                                                                                                \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mModerate (41-70 dB)\u001b[0m: Requires hearing aids to understand normal speech; relies on speechreading cues.        \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mSevere (71-90 dB)\u001b[0m: Understanding normal speech is very challenging even with aids; may hear loud sounds at   \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0mclose distances.                                                                                             \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mProfound (91 dB and above)\u001b[0m: Limited ability to understand conversational speech; often utilize cochlear      \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0mimplants rather than traditional hearing aids.                                                               \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1mTypes of Hearing Loss\u001b[0m:                                                                                          \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mConductive\u001b[0m: Occurs when sound cannot travel freely through the outer and middle ear.                         \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mSensorineural\u001b[0m: Caused by issues within the inner ear or auditory nerve, often permanent.                     \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mMixed\u001b[0m: Combination of conductive and sensorineural loss.                                                     \n",
       "\u001b[1;33m 3 \u001b[0m\u001b[1mAudiogram\u001b[0m: Results are represented graphically on an audiogram, which illustrates the degree of hearing loss    \n",
       "\u001b[1;33m   \u001b[0macross various frequencies and can show if the loss is symmetrical (similar in both ears) or asymmetrical       \n",
       "\u001b[1;33m   \u001b[0m(different in each ear).                                                                                        \n",
       "\n",
       "These methods help determine the type and severity of hearing loss, guiding appropriate interventions and support. \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[Assistant]:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34m[\u001b[0m\u001b[1;34mAssistant\u001b[0m\u001b[1;34m]\u001b[0m\u001b[1;34m:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">I couldn't find any specific positive news stories in the documents you uploaded. If you're looking for uplifting  \n",
       "stories from current events or other sources, you might want to check dedicated news websites or platforms that    \n",
       "focus on positive news. If there's something specific you'd like me to help with, please let me know!              \n",
       "</pre>\n"
      ],
      "text/plain": [
       "I couldn't find any specific positive news stories in the documents you uploaded. If you're looking for uplifting  \n",
       "stories from current events or other sources, you might want to check dedicated news websites or platforms that    \n",
       "focus on positive news. If there's something specific you'd like me to help with, please let me know!              \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[Assistant]:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34m[\u001b[0m\u001b[1;34mAssistant\u001b[0m\u001b[1;34m]\u001b[0m\u001b[1;34m:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">It seems you've uploaded files again. How can I assist you with them?                                              \n",
       "</pre>\n"
      ],
      "text/plain": [
       "It seems you've uploaded files again. How can I assist you with them?                                              \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Thank you for chatting!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mThank you for chatting!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from rich.console import Console\n",
    "from rich.markdown import Markdown\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not openai_api_key:\n",
    "    openai_api_key = input(\"Please enter your OpenAI API key: \")\n",
    "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "\n",
    "client = openai.OpenAI(api_key=openai_api_key)\n",
    "console = Console()\n",
    "\n",
    "# Vector store ID (from the provided documentation)\n",
    "VECTOR_STORE_ID = \"vs_6801d393c83c819184cad189cc621a23\"\n",
    "\n",
    "def print_markdown(text):\n",
    "    \"\"\"Print text as markdown.\"\"\"\n",
    "    console.print(Markdown(text))\n",
    "\n",
    "def chat_with_file_search():\n",
    "    \"\"\"Main chat loop with file search capabilities.\"\"\"\n",
    "    console.print(\"[bold green]File Search Enabled Chat[/bold green]\")\n",
    "    console.print(\"[italic]Type 'exit' to quit the chat[/italic]\")\n",
    "    console.print()\n",
    "    \n",
    "    previous_response_id = None\n",
    "    \n",
    "    while True:\n",
    "        # Get user input\n",
    "        user_input = input(\"\\n[You]: \")\n",
    "        \n",
    "        if user_input.lower() == 'exit':\n",
    "            console.print(\"[bold green]Thank you for chatting![/bold green]\")\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            # Create a response with file search tool\n",
    "            response = client.responses.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                input=user_input,\n",
    "                previous_response_id=previous_response_id,\n",
    "                tools=[{\n",
    "                    \"type\": \"file_search\",\n",
    "                    \"vector_store_ids\": [VECTOR_STORE_ID]\n",
    "                }],\n",
    "                include=[\"file_search_call.results\"]\n",
    "            )\n",
    "            \n",
    "            # Save the response ID for conversation continuity\n",
    "            previous_response_id = response.id\n",
    "            \n",
    "            # Print the assistant's response\n",
    "            console.print(\"\\n[Assistant]:\", style=\"bold blue\")\n",
    "            print_markdown(response.output_text)\n",
    "            \n",
    "            # If file search was used, print the citations\n",
    "            if hasattr(response, 'file_search_calls') and response.file_search_calls:\n",
    "                console.print(\"\\n[Citations]:\", style=\"bold yellow\")\n",
    "                for file_search_call in response.file_search_calls:\n",
    "                    if hasattr(file_search_call, 'search_results') and file_search_call.search_results:\n",
    "                        for i, result in enumerate(file_search_call.search_results, 1):\n",
    "                            console.print(f\"[{i}] File: {result.file.filename}\")\n",
    "                            console.print(f\"    Excerpt: {result.text[:100]}...\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            console.print(f\"\\n[bold red]Error: {str(e)}[/bold red]\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Check if the API key is valid\n",
    "    try:\n",
    "        client.models.list()\n",
    "        chat_with_file_search()\n",
    "    except Exception as e:\n",
    "        console.print(f\"[bold red]Failed to initialize: {str(e)}[/bold red]\")\n",
    "        console.print(\"[bold yellow]Make sure your API key is correct and has access to the file search feature.[/bold yellow]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578c6e38",
   "metadata": {},
   "source": [
    "Can you describe how hearing loss is measured?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408c9e4b",
   "metadata": {},
   "source": [
    "what are some positive news today?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e77bef",
   "metadata": {},
   "source": [
    "After conclusing the chatbot, the tokens spent, amounted to 87,923 - at a cost of $0.03 - Where:\n",
    "Spend categories:\n",
    "\n",
    "    - LLM UTILISATION (GPT 4o mini) INPUT           = $0.007\n",
    "    - LLM UTILISATION (GPT 4o mini) OUTPUT          = $0.001\n",
    "    - LLM UTILISATION (GPT 4o mini) cached input    = $0.003\n",
    "    - FILE SEARCH TOOL CALLS                        = $0.015 \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
